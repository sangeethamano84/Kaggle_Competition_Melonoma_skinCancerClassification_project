{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project, I will show how one can finetune EfficientNet-B7 to detect Melanoma (a variety of skin cancer) from images. This problem is important because fast and accurate automated diagnosis can help reduce burden on doctors and let them focus on curing patients. I will use the Efficientnet Pytorch package to get the pretrained EfficientNet-B7 model and PyTorch XLA to train the model on TPU. At the end, we will run inference on the test set and test the model's predictions on some sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the groundÂ¶\n",
    "In this section, we will prepare the ground to train and test the model by installing packages, setting hyperparameters, and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "Now, we import all the libraries we need.\n",
    "colored, matplotlib, tqdm, and plotly for visualization.\n",
    "numpy, pandas, torch, torchvision, albumentations, and efficientnet_pytorch for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5aaafb878c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle_datasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKaggleDatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_datasets'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "     \n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "DATASET = '512x512-melanoma-tfrecords-70k-images'\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to train and test images\n",
    "train_img_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\n",
    "test_img_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/train.csv\"))\n",
    "test = pd.DataFrame(pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are around 33k training images and about 10k testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying nan values in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set : Sex, age and anatomy_site have missing values.\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set : Anatomy_site have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop nan in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop nan in test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding unique patient in the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['patient_id'].nunique(), test[\"patient_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This means that out of 33,126 registered entries in the training set, only 2,056 are unique implying that some patients are diagnosed with multiple marks.\n",
    "\n",
    "Same goes for the test set where we have only 690 unique values out of collection of 10,982."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Observation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malignant VS Benign cases - OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant = len(train[train[\"target\"] == 1])\n",
    "benign = len(train[train[\"target\"] == 0])\n",
    "\n",
    "labels = [\"Malignant\", \"Benign\"] \n",
    "size = [malignant, benign]\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.pie(size, labels = labels, shadow = True, startangle = 90, colors = [\"r\", \"g\"])\n",
    "plt.title(\"Malignant VS Benign Cases\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Male VS Female Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_males = len(train[train[\"sex\"] == \"male\"])\n",
    "train_females  = len(train[train[\"sex\"] == \"female\"])\n",
    "\n",
    "test_males = len(test[test[\"sex\"] == \"male\"])\n",
    "test_females  = len(test[test[\"sex\"] == \"female\"])\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.countplot(x='sex',data=train,ax=ax[0])\n",
    "ax[0].set_xlabel(\" \")\n",
    "ax[0].set_title(\"Gender counts in train set\")\n",
    "\n",
    "print(\"Number of males in training set = \", train_males)\n",
    "print(\"Number of females in training set= \", train_females)\n",
    "sns.countplot(x='sex',data=test,ax=ax[1])\n",
    "ax[1].set_xlabel(\" \")\n",
    "ax[1].set_title(\"Gender counts in test set\")\n",
    "print(\"Number of males in testing set = \", test_males)\n",
    "print(\"Number of females in testing set= \", test_females)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Malignant male cases VS female cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_malignant  = train[train[\"target\"] == 1]\n",
    "train_malignant_males = len(train_malignant[train_malignant[\"sex\"] == \"male\"])\n",
    "train_malignant_females  = len(train_malignant[train_malignant[\"sex\"] == \"female\"])\n",
    "\n",
    "labels = [\"Malignant Male Cases\", \"Malignant Female Cases\"] \n",
    "size = [train_malignant_males, train_malignant_females]\n",
    "explode = [0.1, 0.0]\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.pie(size, labels = labels, explode = explode, shadow = True, startangle = 90, colors = [\"g\", \"b\"])\n",
    "plt.title(\"Malignant Male VS Female Cases\", fontsize = 18)\n",
    "plt.legend()\n",
    "print(\"Malignant Male Cases = \", train_malignant_males)\n",
    "print(\"Malignant Female Cases = \", train_malignant_females)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benign male cases VS female cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign  = train[train[\"target\"] == 0]\n",
    "\n",
    "train_benign_males = len(train_benign[train_benign[\"sex\"] == \"male\"])\n",
    "train_benign_females  = len(train_benign[train_benign[\"sex\"] == \"female\"]) \n",
    "\n",
    "labels = [\"Benign Male Cases\", \"Benign Female Cases\"] \n",
    "size = [train_benign_males, train_benign_females]\n",
    "explode = [0.1, 0.0]\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.pie(size, labels = labels, explode = explode, shadow = True, startangle = 90, colors = [\"g\", \"y\"])\n",
    "plt.title(\"Benign Male VS Benign Female Cases\", fontsize = 18)\n",
    "plt.legend()\n",
    "print(\"Benign Male Cases = \", train_benign_males)\n",
    "print(\"Benign Female Cases = \", train_benign_females)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Cancer VS Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_versus_sex = train.groupby([\"benign_malignant\",\"sex\"]).size()\n",
    "print(cancer_versus_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_versus_sex = cancer_versus_sex.unstack(level = 1) / len(train) * 100\n",
    "print(cancer_versus_sex)\n",
    "print(type(cancer_versus_sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "sns.set_context(\"paper\", rc={\"font.size\":12,\"axes.titlesize\":20,\"axes.labelsize\":18})   \n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.heatmap(cancer_versus_sex, annot=True, cmap=\"icefire\", cbar=True)\n",
    "plt.title(\"Cancer VS Sex Heatmap Analysis Normalized\", fontsize = 18)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing of Age Vs Cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\", rc={\"font_size\":12,\"axes.titlesize\":20,\"axes.labelsize\":18})   \n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.boxplot(train[\"benign_malignant\"], train[\"age_approx\"], palette=\"icefire\")\n",
    "plt.title(\"Age VS Cancer Boxplot Analysis\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference :Â¶\n",
    "* The malignant cases belong to relatively higher age group.\n",
    "* Age might prove to be a contributing factor in deciding whether the case is malignant or benign.\n",
    "* From sex analysis we can hypothesize that sex might be a deciding factor as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anatom_site_general_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = train.anatom_site_general_challenge.value_counts().sort_values(ascending=False)\n",
    "temp_test = test.anatom_site_general_challenge.value_counts().sort_values(ascending=False)\n",
    "print(\"Anatom_Site valuecounts for train data\",temp_train)\n",
    "print(\"Anatom_Site valuecounts for test data\",temp_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.barplot(x=temp_train.index.values, y=temp_train.values,ax=ax[0])\n",
    "ax[0].set_xlabel(\" \")\n",
    "labels = ax[0].get_xticklabels()\n",
    "ax[0].set_xticklabels(labels, rotation=90)\n",
    "ax[0].set_title(\"Image location in train set\")\n",
    "\n",
    "sns.barplot(x=temp_test.index.values, y=temp_test.values,ax=ax[1])\n",
    "ax[1].set_xlabel(\" \")\n",
    "labels = ax[1].get_xticklabels()\n",
    "ax[1].set_xticklabels(labels, rotation=90)\n",
    "ax[1].set_title(\"Image location in test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like majority of the cases are observed at the torso, and after that the extremities of the body (upper/lower) in both the training and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age distribution in train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2,figsize=(20,7))\n",
    "sns.countplot(x=\"age_approx\", data= train,ax=ax[0])\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_title(\"Age distribution in train set\")\n",
    "sns.countplot(x=\"age_approx\", data=test, ax=ax[1])\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[1].set_title(\"Age distribution in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ages_benign = train.loc[train[\"target\"] == 0, \"age_approx\"]\n",
    "train_ages_malignant = train.loc[train[\"target\"] == 1 , \"age_approx\"]\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.kdeplot(train_ages_benign, label = \"Benign\", shade = True, legend = True, cbar = True)\n",
    "sns.kdeplot(train_ages_malignant, label = \"Malignant\", shade = True, legend = True, cbar = True)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Age Of The Patients\", fontsize = 18)\n",
    "plt.ylabel(\"Probability Density\", fontsize = 18)\n",
    "plt.grid(which = \"minor\", axis = \"both\")\n",
    "plt.title(\"Probabilistic Age Distribution In Training Set\", fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of patients and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No of samples:  ' + str(train.image_name.nunique()))\n",
    "print('No of patients: ' + str(train.patient_id.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No of samples taken from patients frequency\n",
    "Observing the number of patients and no of total samples,I came to the follwoing insights.\n",
    "\n",
    "All the patients gave at least 2 samples.\n",
    "Maximum no of sample taken from a single patient is 115.\n",
    "On an average each patient gave 16 samples\n",
    "Median of samples of image per patient is 12\n",
    "Mode of samples of image per patient is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_freq_per_patient = train.groupby(['patient_id']).count()['image_name']\n",
    "plt.hist(image_freq_per_patient.tolist(), bins = image_freq_per_patient.nunique())\n",
    "plt.xlabel('No of samples per patient')\n",
    "plt.ylabel('No of patients')\n",
    "plt.show()\n",
    "print('Minimum no of sample taken from  single patient', image_freq_per_patient.min())\n",
    "print('Maximum no of sample taken from  single patient', image_freq_per_patient.max())\n",
    "print('There are ',int( image_freq_per_patient.mean()), ' samples taken from each patients on average')\n",
    "print('Median of no. of samples taken from  single patient', int(image_freq_per_patient.median()))\n",
    "print('Mode of no. of samples taken from  single patient', int(image_freq_per_patient.mode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we observe that among the unique patients providing samples,\n",
    "\n",
    "Melanoma is more prevalant in Women\n",
    "Among the Male patients, almost 24% are at malignant stage\n",
    "On the other hand, among Femele patients, about 17% are at malignant stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['benign_malignant', 'sex']).nunique()['patient_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_sex = train.groupby(['sex', 'benign_malignant']).nunique()['patient_id'].tolist()\n",
    "\n",
    "labels = ['Benign', 'Malignant']\n",
    "benign_data = category_sex[0:2]\n",
    "maglignant_data = category_sex[2:4]\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, benign_data, width, label='Male')\n",
    "rects2 = ax.bar(x + width/2, maglignant_data, width, label='Female')\n",
    "ax.set_ylabel('No of patients')\n",
    "ax.set_title('Patient Count by Benign and Malignant with Sex')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot EncodingÂ¶\n",
    "Transforming all categorical features un numerical.\n",
    "\n",
    "Note1: sex, anatomy, diagnosis need to be encoded.\n",
    "\n",
    "Note2: benign_malignant column will be dropped, as the information is already in the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN ===\n",
    "to_encode = ['sex', 'anatom_site_general_challenge', 'diagnosis']\n",
    "encoded_all = []\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in to_encode:\n",
    "    encoded = label_encoder.fit_transform(train[column])\n",
    "    encoded_all.append(encoded)\n",
    "    \n",
    "train['sex'] = encoded_all[0]\n",
    "train['anatom_site_general_challenge'] = encoded_all[1]\n",
    "train['diagnosis'] = encoded_all[2]\n",
    "\n",
    "if 'benign_malignant' in train.columns : train.drop(['benign_malignant'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST ===\n",
    "to_encode = ['sex', 'anatom_site_general_challenge']\n",
    "encoded_all = []\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in to_encode:\n",
    "    encoded = label_encoder.fit_transform(test[column])\n",
    "    encoded_all.append(encoded)\n",
    "    \n",
    "test['sex'] = encoded_all[0]\n",
    "test['anatom_site_general_challenge'] = encoded_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = train[\"image_name\"].values\n",
    "image_names = image_names + \".jpg\"\n",
    "image_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We generate 4 random samples from the training data set. These 4 samples are taken from the aforementioned array of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_images = [np.random.choice(image_names) for i in range(4)] # Generates a random sample from a given 1-D array\n",
    "random_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Earlier we extracted paths of all directories. So, we will access these images from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/kaggle/input/siim-isic-melanoma-classification/jpeg/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "for i in range(4) : \n",
    "    plt.subplot(2, 2, i + 1) \n",
    "    image = cv2.imread(os.path.join(train_dir, random_images[i]))\n",
    "    # cv2 reads images in BGR format. Hence we convert it to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    plt.grid(True)\n",
    "# Automatically adjust subplot parameters to give specified padding.\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of color distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benign Cases :\n",
    "\n",
    "Since we have a lot of images here, hence we randomly sample only a thousand of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign Cases\n",
    "benign = train[train[\"target\"] == 0] \n",
    "image_names = benign[\"image_name\"].values\n",
    "image_names = image_names + \".jpg\"\n",
    "benign_image_list = [np.random.choice(image_names) for i in tqdm(range(1000))]\n",
    "\n",
    "red = []\n",
    "green = [] \n",
    "blue = []\n",
    "\n",
    "for image_name in tqdm(benign_image_list) : \n",
    "    image = cv2.imread(os.path.join(train_dir, image_name))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mean_red = np.mean(image[:,:,0])\n",
    "    mean_green = np.mean(image[:,:,1])\n",
    "    mean_blue = np.mean(image[:,:,2])\n",
    "    \n",
    "    red.append(mean_red)\n",
    "    green.append(mean_green)\n",
    "    blue.append(mean_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness in EDA :\n",
    "Skewness is the measure of symmetry or asymmetry of a data distribution. A distribution or data set is said to be symmetric if it looks same to the left and right point of the center.\n",
    "\n",
    "Types of Skewness :\n",
    "Skewness is generally classified into 2 broad categories-\n",
    "\n",
    "Right skewness or Positive skewness\n",
    "Left skewness or Negative skewness\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis : Kurtosis is the characteristics of being flat or peaked. It is a measure whether data is heavy- tailed or light-tailed in a normal distribution\n",
    "\n",
    "A large kurtosis value often mean that the tails of the distributions are getting toward more extreme values than the tails of normal distributions. This may lead to a length of 6 or 7 standard deviation from the mean. Similarly, If the kurtosis value is very low, then the tails of the distributions will be less lengthier than the those of a normal distribution (less than 3 standard deviation).\n",
    "\n",
    "A large value of kurtosis is often considered as more risky because data may tend to give an outlier value as outcome with greater distance from the mean if applied to any machine learning algorithm.\n",
    "\n",
    "Types of Kurtosis : \n",
    "\n",
    "It is very difficult to interpret and analyse the data which is skewed.\n",
    "\n",
    "Some Transformations for highly skewed data : We can perform a number of transformations so that the data information remains preserved while at the same time some symmetric nature starts developing in its distribution.\n",
    "\n",
    "Taking the square root of each data point and plotting it again. Taking the cube root of each data point and plotting it again. Taking the logarithm of each data point and plotting it again. Taking the reciprocal of each data point and plotting it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel plotting for Benign cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#red channel plot\n",
    "range_of_spread = max(red) - min(red)\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.rc(\"font\", weight = \"bold\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = sns.distplot(red, hist = True, kde = True, label = \"Mean Red Channel Intensities\", color = \"r\")\n",
    "fig.set(xlabel = \"Mean red channel intensities observed in each image (Sample size = 1000)\",\n",
    "        ylabel = \"Probability Density\")\n",
    "plt.title(\"Spread Of Red Channel In Benign Cases\", fontsize = 18)\n",
    "plt.legend()\n",
    "print(\"The range of spread = {:.2f}\".format(range_of_spread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#green channel plot\n",
    "range_of_spread = max(green) - min(green)\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.rc(\"font\", weight = \"bold\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = sns.distplot(green, hist = True, kde = True, label = \"Mean Green Channel Intensities\", color = \"g\")\n",
    "fig.set(xlabel = \"Mean green channel intensities observed in each image (Sample size = 1000)\",\n",
    "        ylabel = \"Probability Density\") \n",
    "plt.title(\"Spread Of Green Channel In Benign Cases\", fontsize = 18)\n",
    "plt.legend()\n",
    "print(\"The range of spread = {:.2f}\".format(range_of_spread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blue channel plot\n",
    "range_of_spread = max(blue) - min(blue)\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.rc(\"font\", weight = \"bold\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = sns.distplot(blue, hist = True, kde = True, label = \"Mean Blue Channel Intensities\", color = \"b\")\n",
    "fig.set(xlabel = \"Mean blue channel intensities observed in each image (Sample size = 1000)\",\n",
    "        ylabel = \"Probability Density\") \n",
    "plt.title(\"Spread Of Blue Channel In Benign Cases\", fontsize = 18)\n",
    "plt.legend()\n",
    "print(\"The range of spread = {:.2f}\".format(range_of_spread))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Spread Of Channels In Benign Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plt.rc(\"font\", weight = \"bold\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = sns.distplot(blue, hist = False, kde = True, label = \"Mean Blue Channel Intensities\", color = \"b\")\n",
    "fig = sns.distplot(red, hist = False, kde = True, label = \"Mean Red Channel Intensities\", color = \"r\")\n",
    "fig = sns.distplot(green, hist = False, kde = True, label = \"Mean Green Channel Intensities\", color = \"g\")\n",
    "\n",
    "fig.set(xlabel = \"Mean channel intensities observed in each image (Sample size = 1000)\",\n",
    "        ylabel = \"Probability Density\") \n",
    "plt.title(\"Spread Of Channels In Benign Cases\", fontsize = 18)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malignant Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up the memory\n",
    "del red\n",
    "del green\n",
    "del blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malignant Cases\n",
    "malignant = train[train[\"target\"] == 1] \n",
    "image_names = malignant[\"image_name\"].values\n",
    "image_names = image_names + \".jpg\"\n",
    "benign_image_list = [np.random.choice(image_names) for i in tqdm(range(len(image_names)))]\n",
    "\n",
    "red = []\n",
    "green = [] \n",
    "blue = []\n",
    "\n",
    "for image_name in tqdm(benign_image_list) : \n",
    "    image = cv2.imread(os.path.join(train_dir, image_name))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mean_red = np.mean(image[:,:,0])\n",
    "    mean_green = np.mean(image[:,:,1])\n",
    "    mean_blue = np.mean(image[:,:,2])\n",
    "    \n",
    "    red.append(mean_red)\n",
    "    green.append(mean_green)\n",
    "    blue.append(mean_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread Of Channels In Malignant Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plt.rc(\"font\", weight = \"bold\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = sns.distplot(blue, hist = False, kde = True, label = \"Mean Blue Channel Intensities\", color = \"b\")\n",
    "fig = sns.distplot(red, hist = False, kde = True, label = \"Mean Red Channel Intensities\", color = \"r\")\n",
    "fig = sns.distplot(green, hist = False, kde = True, label = \"Mean Green Channel Intensities\", color = \"g\")\n",
    "\n",
    "fig.set(xlabel = \"Mean channel intensities observed in each image (Sample size = 1000)\",\n",
    "        ylabel = \"Probability Density\") \n",
    "plt.title(\"Spread Of Channels In Malignant Cases\", fontsize = 18)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, we observe that in both the cases the component of red spikes the most, whereas Blue and Green are close to each other. All the channels also appears to be a bit negatively skewed.\n",
    "\n",
    "### Hence, the channel distribution won't be a powerful feature to differentiate between the malignant and benign cases.**\n",
    "\n",
    "Kutosis of this distribution is manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect() # free up the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "SIZE = [512,512]\n",
    "LR = 0.00004\n",
    "EPOCHS = 12\n",
    "WARMUP = 5\n",
    "WEIGHT_DECAY = 0\n",
    "LABEL_SMOOTHING = 0.05\n",
    "TTA = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Data Filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "seed_everything(SEED)\n",
    "train_filenames = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n",
    "test_filenames = tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames,valid_filenames = train_test_split(train_filenames,test_size = 0.2,random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3) \n",
    "    image = tf.cast(image, tf.float32)/255.0\n",
    "    image = tf.reshape(image, [*SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def data_augment(image, label=None, seed=SEED):\n",
    "    image = tf.image.rot90(image,k=np.random.randint(4))\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed)\n",
    "    image = tf.image.random_flip_up_down(image, seed=seed)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64),  }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['target'], tf.int32)\n",
    "    return image, label \n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string), }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    image_name = example['image_name']\n",
    "    return image, image_name\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = (tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n",
    "              .with_options(ignore_order)\n",
    "              .map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO))\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "def plot_transform(num_images):\n",
    "    plt.figure(figsize=(30,10))\n",
    "    x = load_dataset(train_filenames, labeled=False)\n",
    "    image,_ = iter(x).next()\n",
    "    for i in range(1,num_images+1):\n",
    "        plt.subplot(1,num_images+1,i)\n",
    "        plt.axis('off')\n",
    "        image = data_augment(image=image)\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transform(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (load_dataset(train_filenames, labeled=True)\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .shuffle(SEED)\n",
    "    .batch(BATCH_SIZE,drop_remainder=True)\n",
    "    .repeat()\n",
    "    .prefetch(AUTO))\n",
    "\n",
    "valid_dataset = (load_dataset(valid_filenames, labeled=True)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        efn.EfficientNetB7(input_shape=(*SIZE, 3),weights='imagenet',pooling='avg',include_top=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = LABEL_SMOOTHING),\n",
    "        metrics=['accuracy',tf.keras.metrics.AUC(name='auc')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_schedule_with_warmup(lr,num_warmup_steps, num_training_steps, num_cycles=0.5):\n",
    "    def lrfn(epoch):\n",
    "        if epoch < num_warmup_steps:\n",
    "            return (float(epoch) / float(max(1, num_warmup_steps))) * lr\n",
    "        progress = float(epoch - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr\n",
    "\n",
    "    return tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "lr_schedule= get_cosine_schedule_with_warmup(lr=LR,num_warmup_steps=WARMUP,num_training_steps=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "        STEPS_PER_EPOCH = count_data_items(train_filenames) // BATCH_SIZE\n",
    "        history = model.fit(\n",
    "            train_dataset, \n",
    "            epochs=EPOCHS, \n",
    "            callbacks=[lr_schedule],\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            validation_data=valid_dataset)\n",
    "\n",
    "        string = 'Train acc:{:.4f} Train loss:{:.4f} AUC: {:.4f}, Val acc:{:.4f} Val loss:{:.4f} Val AUC: {:.4f}'.format( \\\n",
    "            model.history.history['accuracy'][-1],model.history.history['loss'][-1],\\\n",
    "            model.history.history['auc'][-1],\\\n",
    "            model.history.history['val_accuracy'][-1],model.history.history['val_loss'][-1],\\\n",
    "            model.history.history['val_auc'][-1])\n",
    "\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Based on Test Time Augmentation (TTA)\n",
    "* Data augmentation technique for the test dataset, where multiple augmentaed copies of images in dataset is created with zoom, flip and shifts\n",
    "* The artificially expanded training dataset can result in a more skillful model, as often the performance of deep learning models continues to scale in concert with the size of the training dataset\n",
    "* The model makes prediction for each and then ensemble of the predictions are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_images = count_data_items(test_filenames)\n",
    "submission_df = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\n",
    "for i in range(TTA):\n",
    "    test_dataset = (load_dataset(test_filenames, labeled=False,ordered=True)\n",
    "    .map(data_augment, num_parallel_calls=AUTO)  \n",
    "    .batch(BATCH_SIZE))\n",
    "    test_dataset_images = test_dataset.map(lambda image, image_name: image)\n",
    "    test_dataset_image_name = test_dataset.map(lambda image, image_name: image_name).unbatch()\n",
    "    test_ids = next(iter(test_dataset_image_name.batch(num_test_images))).numpy().astype('U')\n",
    "    test_pred = model.predict(test_dataset_images, verbose=1) \n",
    "    pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(test_pred)})\n",
    "    temp = submission_df.copy()   \n",
    "    del temp['target']  \n",
    "    submission_df['target'] += temp.merge(pred_df,on=\"image_name\")['target']/TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)\n",
    "pd.Series(np.round(submission_df['target'].values)).value_counts() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
